= Compiler Design and Implementation
Emilio Domínguez_Sánchez <emilio.dominugezs@um.es>; Rubén Gaspar_Marco <ruben.gasparm@um.es>
v1.0, May 17, 2020: As presented to our teacher Eduardo Martínez Gracia
:stem: latexmath
:source-highlighter: prettify
:toc:

== Introduction
This project corresponds to the practical part of the subject "`Compiladores`" (Compilers).
The subject usually corresponds to the second year of Computer Engineering.
Nonetheless, it is a third year subject for the students who
decide to enroll in the simultaneous studies program of the University of Murcia.
Both of us are currently studying Mathematics and Computer Engineering.

Our initial task was writing a small compiler for a subset of Pascal's language.
The essential features of the language were

* Differentiation of constants and variables
* Flow control through the `if`, `for` and `while` statements
* Code reuse through `function` definitions

But it was greatly simplified in comparison to Pascal.

* Restricted to a single type: integer values
* Absent of relational operators

We decided we wanted to focus on this project and implement a language with more features

* Support for multiple types
* Type checking
* Advanced name resolution
** Nested name scopes
** Chronological name scopes which enforce the declaration of a name before its use
** Achronological name scopes which don't
* Return statement
* Operator and function overloading
* Llvm output


We have spent most of the time learning and implementing a good system.
Our focus has always been extensibility.
The time we can dedicate to this subject is limited,
but we were always thinking
_"`If we were to implement this feature from language X,
would it be easy with the code as is right now?`"_.
This document serves the purpose of describing our work and
our view on the code structure of a compiler.


== Compiler Features Overview

=== Rationale of the features supported


== Language and Tools
We were taught in class how to use Bison.
Bison is an Open Source parser generator usually used along Flex,
an Open Source lexical analyzer generator.
Although originally written for the C language,
both Bison and Flex allow you to work with {cpp}.
We chose to use {cpp} because it is a very powerful language and,
being this a new project,
we had no reason to stick to C.

In addition, we used

* https://google.github.io/styleguide/cppguide.html[Google's {cpp} Style Guide]
* https://clang.llvm.org/extra/clang-tidy/[`clang-tidy`]
  as a linter and style checker.
* https://asciidoctor.org/[AsciiDoctor] for writing this document.


== Compiler Parts
Imperative languages share some similarities.
Although they may differ in the implementation,
the usually share the core concepts.

Statement:: Statements are the basic units of a program.
In a typical language,
assignment,
flow control directives
(loops, conditional statements and branching statements) and
function invocations are all statements with their own syntax.
Expression:: Typically, statements take parameters,
and these paramenters are usually expressions.
For example, you can assign a variable a literal value or the sum of two variables.
Both would be valid expressions (for the assignment value).
Function:: A function is a set of statements that can be invoked other parts of the program.
Variable:: A variable is a abstract entity that holds a value which can used (as an expression)
in statements and can also be modified trough some statements (like assignment).

=== Abstraction
We have found that the ability to abstract concepts is key in the design of a compiler.
We can merge many concepts, leading to an easier understanding and simpler logic.

=== Merging concepts
We can define a constant as a name that holds a value that cannot be changed.
When translating to machine code, constants can be allocated in read-only segments
or globally instead of in the stack. However, for programming purposes,
a constant is a variable which cannot be modified.
Whenever we see that a concept can be expressed in terms of another concept in the compiler,
we will find languages which merge both concepts.

For instance, in {cpp} variables declared with the `const` attribute may not be modified,
but they aren't exactly constants.
The reason is that a function can take a constant reference to a variable as a parameter,
which means that the address of memory associated with that variable can be read inside the
function by means of using the variable name,
but the compiler ensures that the variable is not modified,
even though if the variable wasn't declared as `const` in the function that called it,
the same address of memory could be modified there.

As another example, expressions can be thought of as statements.
The reason is that in some languages they can modify the state of the computer,
just as statements.
In general, a statement could be thought as an expression which doesn't return a result,
or expressions could be the statements that did return a result.
In the Lisp family of languages, every statement returns a value that can be used for
another statement. Therefore, there is not a distinction between the two.
We can also shorten the distance between expressions and statements by making the return
type of some statements a special type of which the programmer cannot handle values.

=== Definition and usage
Programming languages serve the purpose of creating programs that
process data and do calculations.
Some languages mantain a structre very similar to assembly.
However, all of them introduce modular entities
that the programmer can customize and use.
Variables can be declared.
Types can be created grouping smaller types.
Functions can be created grouping statements.

It is common that an identifier (a name) is used to refer to this entities.
When this is the case, we usually need to conceptually separate the difference between
the definition,
i.e. the programmer specifies that
there is a function with name `foo` that consists of these statements;
and the usage,
the programmer calls a function defined at some point in the code.
C and {cpp} even diferentiate between declarations and implementations,
where the declaration only specifies how an object can be used
(which parameters does a function take).

The difference must translate to the abstract syntax tree too.
We must have different nodes for a function definition and a function call.
And again, this can be generalized further.
{cpp} considers the construction `name(args)` as an operator and allows overloading it.
Therefore, in {cpp} you can call a function but you can also call a variable whose type
has the operator overloaded.
This is a usage abstraction and gives place to the concept of callable.

== Language Grammar in BNF format
:lambda: &lambda;
[frame=none, grid=none, stripes=none]
|===
|program              | -> | `program` id `(` `)` `;`                      +
                             functions                                     +
                             declarations                                  +
                             compound_statement `.`
|functions            | -> | (function `;`)*
|                     | \| | {lambda}
|function             | -> | `function` id `(` optional_args `)` `:` type  +
                              declarations                                 +
                              compound_statement
|optional_args        | -> | args
|                     | \| | {lambda}
|args                 | -> | single_arg
|                     | \| | args `,` single_arg
|single_arg           | -> | id `:` type
|                     | \| | `const` id `:` type
|type                 | -> | int
|                     | \| | str
| declarations        | -> | declarations `var` idenifiers `:` type `;`
|                     | \| | declarations `const` constants `;`
|                     | \| | {lambda}
| identifiers         | -> | id
|                     | \| | identifiers `,` id
|constants            | -> | id `:=` expression
|                     | \| | constants `,` id `:=` expression
|compound_statement   | -> | `begin`                                       +
                                 optional_statements                       +
                             `end`                                         +
|optional_statements  | -> | statements
|                     | \| | {lambda}
|statements           | -> | statement
|statements           | \| | statements `;` statement

|statement            | -> | id `:=` expression
|                     | \| | `if` expression `then`                        +
                                  statement                                +
|                     | \| | `if` expression `then`                        +
                                  statement                                +
                             `else`                                        +
                                  statement                                +
|                     | \| | `while` expression `then`                     +
                                  statement                                +
|                     | \| | `for` id `:=` expression `to` expression `do` +
                                  statement
|                     | \| | `write` `(` expressions `)`
|                     | \| | `read` `(` identifiers `)`
|                     | \| | compound_statement

|optional_expressions | -> | expressions
|                     | \| | {lambda}
|expressions          | -> | expression
|                     | \| | expressions `,` expression
|expression           | -> | expression `+` expression
|                     | -> | expression `-` expression
|                     | -> | expression `*` expression
|                     | -> | expression `/` expression
|                     | -> | `-` expression
|                     | -> | `(` expression `)`
|                     | -> | id
|                     | -> | int_lit
|                     | -> | str_lit
|                     | -> | id `(` optional_expressions `)`
|===

Where `id`, `int_lit` and `str_lit` are identifiers, int literals and str literals
as recognized by our lexical analyzer.

%TODO Rubén, explica la semántica y que se pueden usar funciones antes de declarar y todo eso

== Implementation I
Designing a language and designing the compiler are completely different tasks.
Designing a language involves choosing its features
(knowing in advance that they can be achieved)
and how they interact.
Designing the compiler is designing an application...
using a programming language.

We believe a natural separation of a compiler is

* The structure known as the abstract syntax tree (AST)
* The algorithms that operate on that structure

However, this separation is rather obvious and provides little help to beginners.
We believe this is a better classification.

* The lexer, which divides the input in tokens.
* The parser, which builds the initial AST from the tokens
* The name resolution algorithms, which bind each identifier with a definition
* The type system structures and algorithms, in charge of types equivalence,
  conversion and other advanced features, such as inheritance
* The semantic correction algorithms, which check things such that the expressions
  and the variable in a typical `for` statement are of the same type.
* The optimization algorithms, which modify the AST
* The translation algorithm, which produces the final result.

This could be a good modularization of a compiler project.
Nevertheless, there are also dependencies between systems.
For example, a name resolution algorithm first applies to identify the possible
functions that can be associated with a function call.
After that, there must be a criteria for choosing which one applies.
However, that algorithm needs to know which types are compatible.
Hence, it can be difficult to separate the name resolution algorithms
from the type system.

=== Variants or Inheritance. The visitor pattern.
As we have already seen, a lot of algorithms in the compiler are related to the AST.
When programming a smaller compiler such as ours,
without a rich type system and without optimization phases,
it might sound reasonable to implement the AST using inheritance.

[quote,,Crafting a Compiler<<check>>]
ASTs for Languages like Java contain ∼50 node types,
and compilers like the GNU Compiler Collection (GCC) have ∼200 phases.

As programmers of a small compiler, we cannot recommend this.
Even in a small compiler you would need to implement 3 to 5 virtual functions
for each node of the AST.
This results in code with the same purpose being dispersed along multiple files.

In addition, declaring an interface for what functions does an expression allow
does not scale properly.
As the complexity increases, a node can start implementing many interfaces.

Our implementation uses {cpp} 17's `std::variant` to simulate the visitor design pattern.
With this approach, an expression is one of many possibilities, instead of a base class.
The approach is similar to using a C union but allows dynamic dispatching as a language feature
thanks to the function `std::visit`,
which automatically invokes the method of a callable that better suits the current object.


.Expression definition
[source,cpp]  
---- 
enum UnaryOperators : char {
    kUnaMinus = '-',
};

enum BinaryOperators : char {
    kPlus     = '+',
    kBinMinus = '-',
    kAsterisk = '*',
    kSlash    = '/',
};

template<UnaryOperators op>  struct UnaOp;
template<BinaryOperators op> struct BinOp;
class Id;
struct IntLit;
struct StrLit;
struct FunCall;
struct NoExp;


using Exp = std::variant<
    UnaOp<kUnaMinus>*,
    BinOp<kPlus>*,
    BinOp<kBinMinus>*,
    BinOp<kAsterisk>*,
    BinOp<kSlash>*,
    RVar,
    IntLit*,
    StrLit*,
    FunCall*,
    NoExp*
>;
----

The AST becomes a very simple data structure which the algorithms are free to modify.

.A function call node
[source,cpp]
----
struct FunCall {
    RFun rfun;
    std::vector<Exp> args;

    FunCall(RFun rfun, std::vector<Exp>&& args) : rfun(rfun), args(args) {  };
};
----

And we can include all the code related to a pass over the AST inside a single class
which packs the methods and the data it needs to act.
This also favors debugging of large systems,
because this type of system doesn't rely on singletons.
We can create as many instances of an optimizer as we want and pass a suite of tests
over plainly ASTs defined by the programmer.

=== AST structure
The definition of the whole AST is divided in four files.

https://github.com/Rvb0rob0t/miniPascal_compiler/blob/master/include/ast_defs.hpp[ast_defs.hpp]::
Contains the basic definitions of the AST.
It contains the supported operators,
the variant expression (`Exp`) and
the variant statement (`Stmt`).

https://github.com/Rvb0rob0t/miniPascal_compiler/blob/master/include/ast.hpp[ast.hpp]::
Contains the AST classes which are objects in the language and have a detailed description
of their implementation as declared by the programmer.
+
These classes are special because they can pack information that is needed for the final translation.
We have also considered a good choice to inherit from these classes,
because in this case the class polymorphism was beneficial.
For example, our builtin operators inherit from `Fun`, the class that represents a function.

https://github.com/Rvb0rob0t/miniPascal_compiler/blob/master/include/expressions.hpp[expressions.hpp]::
Declares the expression nodes.

https://github.com/Rvb0rob0t/miniPascal_compiler/blob/master/include/statements.hpp[statements.hpp]::
Declares the statements structures.


== Implementation II


=== Name Resolution

==== Name Scopes
Big programs consists of thousands of lines of code.
Languages usually offer mechanisms to avoid name conflicts.
Name scopes are an abstraction that group the names in groups,
allowing the same name to belong to different name scopes.

Name scopes usually receive a name that allows to refer to the names
inside that name scope from a different one,
usually by prepending the name with the namescope's name.

We wanted to design a general system that would allow

* Nesting of name scopes
* Exporting an AST with unresolved names
* Using identifiers previous to their declaration (for some use cases)

Regarding the last point,
we thought that this could be a very useful feature to allow the use of
constants and functions previous to their definition.

However, we beleived this was a feature we wouldn't like to apply to every single identifier.
The reason is simple.
Given the following code

[source]
----
def f() {    // namespace of function f
    if () {  // namespace created by a compound statement
        a(); // unresolved name (hasn't been declared at this point)
    }
    int a = 3;
}

def a() {
    
}
----

In a typical imperative language,
the usage of the name `a` would not point to the variable.
Neither it would to the function,
because it was declared afterwards,
but we wanted to maintain the possibility of having name scopes in which
names are not available until you define them.

Our solution is creating two types of name scopes.

Acronological Name Scopes::
In acronological name scopes definitions don't follow any order.
In an advanced system,
this usually would imply that the compiler would not guarantee any order in the initialization.
By definition, any definition or statement could make use of the rest of the names.
Nested name scopes inherit all of the names declared in this name scope,
independent of the moment where they are defined.
Another good name for this type of name scope could be
declaration name scope or parallel name scope.

Cronological Name Scopes::
In cronological name scopes there exists a total order between definitions.
A definition may only use the definitions from the name scope that were defined before it.
The compiler can guarantee the order of initialization and
can easily resolve names during the parsing by
maintaining a stack of active identifiers for each name.
Another good name for this type of name scope could be
implementation name scope or ordered name scope.

Acronological name scopes can be useful for
the global name scope,
classes name scopes and
some user-defined name scopes.
Cronological name scopes can be useful for the body of
functions,
loop statements and
user-defined name scopes where the order of initialization is important.

The implementation inside the compiler is easy if we fix that
acronological name scopes may only be children of an acronological name scope too.
If this is the case the stack of active name scopes at any point in the code
always looks as a sucession of acronological name scopes followed by a sucession of cronological.
When a name is used, the compiler can check the active names
and check if it references an object in a cronological name scope (which must be already defined).
If the top active identifier with this name is not from the top acronological scope,
an identifier in the top cronological scope is created.
At the end of the program, an algorithm can easily alias
identifiers in an acronological scopes which weren't defined to an identifier in a parent scope.
This, precisely, is our implementation.

=== Identifiers
As pointed in the previous section, our design of the language means that
the nodes in the AST cannot point directly to the objects they refer.
The reason is, we only know the name of such an object,
but different objects can have the same names.

Names can be resolved doing a pass over the AST.
To maintain type safety in our code,
we followed this scheme.

[frame=none,grid=none,stripes=none,options="header"]
|===
|Named Abstraction | Name                         | A reference to a named abstraction
|type (`Type`)     |                              | type usage +
                                                    (in the declaration of variables and functions)
|variable (`Var`)  | identifier +
     (uniquely identified by name and name scope) | var usage +
                                                    (as an expression or as a memory location)
|function (`Fun`)  |                              | function call (`FunCall`)
|===

and made use of the following definitions.

.Named references
[source,cpp]
----
union RVar {
    identifiers::Id* id;
    Var* var;

    RVar() {  }
    explicit RVar(identifiers::Id* id) : id(id) {  }
};

union RType {
    identifiers::Id* id;
    Type* ty;

    RType() {  }
    explicit RType(identifiers::Id* id) : id(id) {  }
};

union RFun {
    identifiers::Id* id;
    Fun* fun;

    RFun() {  }
    explicit RFun(identifiers::Id* id) : id(id) {  }
};
----

By using unions, we incur in no extra cost in memory space.
The AST is defined in a way that an expression or statement which uses a variable
has a member of type `RVar` instead of a pointer to a variable object (`Var*`).
During the name resolution pass, we change the reference to point to the object,
whose information is has been referenced inside the `identifiers::Id` class.
Passes that happen after the this one use this references
as if they pointed to the named abstraction.

This is only an implementation detail,
but by using enums instead of generic pointers,
we can benefit of type checking by the compiler and
we can avoid coding static casts everywhere.
In addition, it is clear from a programmer point of view that
`RVar` is a reference to a variable object,
whether this object is currently represented by its identifier or not.

The name system is implemented in three files:

https://github.com/Rvb0rob0t/miniPascal_compiler/blob/master/include/ast_defs.hpp[ast_defs.hpp]::
Contains the definitions of `RType`, `RVar` and `RFun`.

https://github.com/Rvb0rob0t/miniPascal_compiler/blob/master/include/identifiers.hpp[identifiers.hpp]::
Contains the definitions of the `identifiers` name space
(in the code, not in the sense of name space in the compiler).
It defines the classes `NameScope` and `Id` and
contains functions to add and change name scopes during the parsing.

https://github.com/Rvb0rob0t/miniPascal_compiler/blob/master/include/id_resolution.hpp[id_resolution.hpp]::
Contains the class in charge of performing the name resolution and updating the named references
to point to named objects.
We have also used this class to perform semantic checks during the pass
that ensure the program correctness.

=== Semantic Checks
//TODO rubensio

=== Type Handling
We designed our compiler with the idea of being able to support user-defined types.
However, we have not had time to do so.

Fortunately, we designed our compiler with two primitive types.
This means we considered type checking in our design.

=== Code Generation
%TODO Rubén

== Conclusions
%TODO Rubén

=== How to continue the project
Now that we have finished the project,
we would like our teachers to consider the possibility of
allowing future students to continue this project instead of starting from scratch.
The design of the application could receive a few improvements which
we have marked with `//IMPROVEMENT` comments in our source code.
The project can also be used as a reference for future students or
as a project skeleton after removing some parts of code.

These are some of the improvements this compiler could receive

Better Encapsulation::
Although the main parts of the project remain modularized,
we still maintain some global variables,
like a collection of the program string literals.
The AST's root, the struct `Prog`, could be upgraded to a class
which would maintain this kind of state.
State which could also be queried and modified by passes over the AST.

Memory Management::
Right now, the program relies on the AST being freed at the end of execution.
We would encourage future contributors to
understand and modify the code to represent memory ownership.

Output Optimization::
This would be a fresh topic,
since we have not implemented any optimization pass.

Llvm Libraries::
We have implemented a direct translation making use of the llvm language specification.
Instead, it would be useful to translate the program's AST to llvm's AST and make use
of all the available libraries to optimize this code.

New Features::
And of course, complementing the language with new features is important.
In order of importance, we miss

* The ability to declare arrays
* User declared types
* A unique feature,
  such as templates are for {cpp},
  some kind of pattern matching or even
  an inheritance system.

[bibliography]
== References

- [[[craft,1]]] Charles N. Fischer, Ron K. Cytron & Richar J. LeBlanc, Jr. Crafting a Compiler. Addison-Wesley. 2010.
